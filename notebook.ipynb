{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-24T11:37:30.689075Z",
     "start_time": "2025-05-24T11:37:26.358438Z"
    }
   },
   "source": [
    "import os\n",
    "import torchvision.transforms as transforms,datasets\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "from facenet_pytorch import MTCNN\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T11:27:30.345691Z",
     "start_time": "2025-05-24T11:27:30.329221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"✅ GPU доступен!\")\n",
    "    print(f\"Имя устройства: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Количество устройств: {torch.cuda.device_count()}\")\n",
    "    print(f\"Текущий девайс: {torch.cuda.current_device()}\")\n",
    "else:\n",
    "    print(\"❌ GPU не найден, используется CPU.\")"
   ],
   "id": "afef9acc710720e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GPU доступен!\n",
      "Имя устройства: NVIDIA GeForce RTX 3060\n",
      "Количество устройств: 1\n",
      "Текущий девайс: 0\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T11:27:30.780397Z",
     "start_time": "2025-05-24T11:27:30.764788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(torch.__version__)\n",
    "print(torch.version.cuda)  # Должно быть не None\n",
    "print(torch.backends.cudnn.version()) "
   ],
   "id": "1befc8523ee8d1fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0+cu118\n",
      "11.8\n",
      "90100\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T11:27:31.673327Z",
     "start_time": "2025-05-24T11:27:31.657651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class SimpleAutoencoder(nn.Module):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super(SimpleAutoencoder, self).__init__()\n",
    "        H = 200\n",
    "        W = 170\n",
    "        # Encoder: сжимает изображение\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 4, stride=2, padding=1),  # B,32,H/2,W/2\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 4, stride=2, padding=1),  # B,64,H/4,W/4\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1), # B,128,H/8,W/8\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * (H//8) * (W//8), latent_dim)  # сжимаем в латентное пространство\n",
    "        )\n",
    "        \n",
    "        # Decoder: восстанавливает изображение\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128 * (H//8) * (W//8)),\n",
    "            nn.Unflatten(1, (128, H//8, W//8)),\n",
    "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),  # B,64,H/4,W/4\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 4, stride=2, output_padding=1),   # B,32,H/2,W/2\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 3, 4, stride=2, output_padding=1),    # B,3,H,W\n",
    "            nn.Sigmoid()  # если данные нормализованы [0,1]\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        out = reconstructed[:, :, :x.size(2), :x.size(3)]\n",
    "\n",
    "        return out,latent\n"
   ],
   "id": "109e4939fa3a1748",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T11:24:18.112278Z",
     "start_time": "2025-05-24T11:24:18.100880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 4, stride=2, padding=1),  # [B, 32, 100, 85]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 4, stride=2, padding=1),  # [B, 64, 50, 43]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),  # [B, 128, 25, 21]\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_mu = nn.Linear(128 * 25 * 21, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(128 * 25 * 21, latent_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder_input = nn.Linear(latent_dim, 128 * 25 * 22)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),  # [B, 64, 50, 44]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1, output_padding=(0, 1)),  # [B, 32, 100, 88]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 3, 4, stride=2, padding=1, output_padding=(0, 1)),  # [B, 3, 200, 176]\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Кроп до точного размера 200x170\n",
    "        self.crop = lambda x: x[:, :, :, :170]\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        z_flat = self.flatten(z)\n",
    "        mu = self.fc_mu(z_flat)\n",
    "        logvar = self.fc_logvar(z_flat)\n",
    "        latent = self.reparameterize(mu, logvar)\n",
    "\n",
    "        dec_input = self.decoder_input(latent).view(-1, 128, 25, 22)\n",
    "        x_recon = self.decoder(dec_input)\n",
    "        return self.crop(x_recon), mu, logvar\n",
    "\n",
    "    def loss_function(self, recon_x, x, mu, logvar):\n",
    "        recon_loss = F.mse_loss(recon_x, x, reduction='mean')\n",
    "        kld = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return recon_loss + kld * 0.001  # Вес KLD можно менять\n"
   ],
   "id": "9cfa1e3950e3a9b6",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T11:27:34.717431Z",
     "start_time": "2025-05-24T11:27:34.702967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def show_faces(original, reconstructed, n=5):\n",
    "    # original = denormalize(original)\n",
    "    # reconstructed = denormalize(reconstructed)\n",
    "\n",
    "    fig, axes = plt.subplots(2, n, figsize=(15, 5))\n",
    "    for i in range(n):\n",
    "        axes[0, i].imshow(original[i].permute(1, 2, 0).clip(0, 1))\n",
    "        axes[0, i].axis('off')\n",
    "        axes[1, i].imshow(reconstructed[i].permute(1, 2, 0).clip(0, 1))\n",
    "        axes[1, i].axis('off')\n",
    "    axes[0, 0].set_ylabel('Оригинал', fontsize=14)\n",
    "    axes[1, 0].set_ylabel('После A.E.', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "df0f69430e70d558",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T11:27:35.793369Z",
     "start_time": "2025-05-24T11:27:35.620642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_dir = r'C:\\Users\\admin\\.cache\\kagglehub\\datasets\\jessicali9530\\celeba-dataset\\versions\\2\\img_align_celeba\\img_align_celeba'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((200, 170)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# mtcnn = MTCNN(image_size=160, margin=0, device=device)\n",
    "autoencoder = SimpleAutoencoder().to(device)\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Выбираем первые N лиц\n",
    "N = 100\n",
    "images = os.listdir(image_dir)[:N]\n",
    "faces = []"
   ],
   "id": "b592916f17d0e832",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T11:27:40.235610Z",
     "start_time": "2025-05-24T11:27:40.110254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for img_name in tqdm(images):  # images — это список имён файлов\n",
    "    img_path = os.path.join(image_dir, img_name)\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    tensor_img = transform(img)\n",
    "    faces.append(tensor_img)\n",
    "\n",
    "faces = torch.stack(faces).to(device)\n"
   ],
   "id": "22c0d2bc49972de2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1128.61it/s]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T11:28:01.152337Z",
     "start_time": "2025-05-24T11:27:53.657380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mass_loss = []\n",
    "# Тренируем автоэнкодер\n",
    "for epoch in range(10):\n",
    "    for img in faces:\n",
    "        img = img.unsqueeze(0)\n",
    "        autoencoder.train()\n",
    "        output,_ = autoencoder(img)\n",
    "        loss = loss_fn(output, img)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        mass_loss.append(loss.item())\n",
    "    print(f\"Эпоха {epoch+1}, Потери: {np.median(mass_loss):.4f}\")"
   ],
   "id": "ca93f79c95783127",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 1, Потери: 0.0646\n",
      "Эпоха 2, Потери: 0.0571\n",
      "Эпоха 3, Потери: 0.0495\n",
      "Эпоха 4, Потери: 0.0454\n",
      "Эпоха 5, Потери: 0.0427\n",
      "Эпоха 6, Потери: 0.0399\n",
      "Эпоха 7, Потери: 0.0376\n",
      "Эпоха 8, Потери: 0.0352\n",
      "Эпоха 9, Потери: 0.0336\n",
      "Эпоха 10, Потери: 0.0325\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T11:30:43.664423Z",
     "start_time": "2025-05-24T11:30:41.470797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "autoencoder.eval()\n",
    "out,latent = autoencoder(faces)\n",
    "reconstructed = out.detach().cpu()\n",
    "\n",
    "show_faces(faces.cpu(), reconstructed)\n"
   ],
   "id": "6f508f628d12cbea",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T11:32:04.986145Z",
     "start_time": "2025-05-24T11:32:04.970745Z"
    }
   },
   "cell_type": "code",
   "source": "latent = latent.detach().cpu().numpy()",
   "id": "b55bae345b439195",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T11:32:28.037397Z",
     "start_time": "2025-05-24T11:32:28.021950Z"
    }
   },
   "cell_type": "code",
   "source": "latent.shape",
   "id": "e853f42a4c3b906d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 128)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6d0f3d70ec003e83"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
