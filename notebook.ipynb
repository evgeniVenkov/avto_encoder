{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-24T12:33:35.911744Z",
     "start_time": "2025-05-24T12:33:32.531724Z"
    }
   },
   "source": [
    "import os\n",
    "import torchvision.transforms as transforms,datasets\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "from facenet_pytorch import MTCNN\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T12:33:38.153726Z",
     "start_time": "2025-05-24T12:33:38.122836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"✅ GPU доступен!\")\n",
    "    \n",
    "    print(f\"Имя устройства: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Количество устройств: {torch.cuda.device_count()}\")\n",
    "    print(f\"Текущий девайс: {torch.cuda.current_device()}\")\n",
    "else:\n",
    "    print(\"❌ GPU не найден, используется CPU.\")"
   ],
   "id": "afef9acc710720e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GPU доступен!\n",
      "Имя устройства: NVIDIA GeForce RTX 3060\n",
      "Количество устройств: 1\n",
      "Текущий девайс: 0\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T12:29:22.961276Z",
     "start_time": "2025-05-24T12:29:22.951157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(torch.__version__)\n",
    "print(torch.version.cuda)  # Должно быть не None\n",
    "print(torch.backends.cudnn.version()) "
   ],
   "id": "1befc8523ee8d1fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0+cu118\n",
      "11.8\n",
      "90100\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T12:13:11.352032Z",
     "start_time": "2025-05-24T12:13:11.334899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, images_list, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.images_list = images_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images_list[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img"
   ],
   "id": "2f24ca9c679a9e81",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T12:33:41.239796Z",
     "start_time": "2025-05-24T12:33:41.218997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class SimpleAutoencoder(nn.Module):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super(SimpleAutoencoder, self).__init__()\n",
    "        H = 200\n",
    "        W = 170\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 4, stride=2, padding=1),  # B,32,H/2,W/2\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 4, stride=2, padding=1),  # B,64,H/4,W/4\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1), # B,128,H/8,W/8\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * (H//8) * (W//8), latent_dim)  \n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128 * (H//8) * (W//8)),\n",
    "            nn.Unflatten(1, (128, H//8, W//8)),\n",
    "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),  # B,64,H/4,W/4\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 4, stride=2, output_padding=1),   # B,32,H/2,W/2\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 3, 4, stride=2, output_padding=1),    # B,3,H,W\n",
    "            nn.Sigmoid()  \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        out = reconstructed[:, :, :x.size(2), :x.size(3)]\n",
    "\n",
    "        return out,latent\n"
   ],
   "id": "109e4939fa3a1748",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T12:33:44.137200Z",
     "start_time": "2025-05-24T12:33:44.128223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def show_faces(original, reconstructed, n=5):\n",
    "\n",
    "    fig, axes = plt.subplots(2, n, figsize=(15, 5))\n",
    "    for i in range(n):\n",
    "        axes[0, i].imshow(original[i].permute(1, 2, 0).clip(0, 1))\n",
    "        axes[0, i].axis('off')\n",
    "        axes[1, i].imshow(reconstructed[i].permute(1, 2, 0).clip(0, 1))\n",
    "        axes[1, i].axis('off')\n",
    "    axes[0, 0].set_ylabel('Оригинал', fontsize=14)\n",
    "    axes[1, 0].set_ylabel('После A.E.', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "df0f69430e70d558",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T12:33:47.406771Z",
     "start_time": "2025-05-24T12:33:46.823978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((200, 170)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "autoencoder = SimpleAutoencoder().to(device)\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "image_dir = r'C:\\Users\\admin\\.cache\\kagglehub\\datasets\\jessicali9530\\celeba-dataset\\versions\\2\\img_align_celeba\\img_align_celeba'\n",
    "images = os.listdir(image_dir)\n",
    "\n",
    "\n",
    "dataset = ImageDataset(image_dir, images, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n"
   ],
   "id": "b592916f17d0e832",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 17\u001B[0m\n\u001B[0;32m     13\u001B[0m image_dir \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mUsers\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124madmin\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m.cache\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mkagglehub\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mdatasets\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mjessicali9530\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mceleba-dataset\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mversions\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m2\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mimg_align_celeba\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mimg_align_celeba\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     14\u001B[0m images \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mlistdir(image_dir)\n\u001B[1;32m---> 17\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mImageDataset\u001B[49m(image_dir, images, transform\u001B[38;5;241m=\u001B[39mtransform)\n\u001B[0;32m     18\u001B[0m dataloader \u001B[38;5;241m=\u001B[39m DataLoader(dataset, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, num_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'ImageDataset' is not defined"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T12:33:54.226786Z",
     "start_time": "2025-05-24T12:33:54.067186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((200, 170)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "faces = []\n",
    "image_dir = r'C:\\Users\\admin\\.cache\\kagglehub\\datasets\\jessicali9530\\celeba-dataset\\versions\\2\\img_align_celeba\\img_align_celeba'\n",
    "images = os.listdir(image_dir)\n",
    "\n",
    "for img_name in tqdm(images[:50]):  # images — это список имён файлов\n",
    "    img_path = os.path.join(image_dir, img_name)\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    tensor_img = transform(img)\n",
    "    faces.append(tensor_img)\n",
    "\n",
    "faces = torch.stack(faces).to(device)\n"
   ],
   "id": "22c0d2bc49972de2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 915.25it/s]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mass_loss = []\n",
    "# Тренируем\n",
    "\n",
    "for epoch in range(10):\n",
    "    loop = tqdm(dataloader, desc=f\"Epoch {epoch+1}\")\n",
    "    for bath in loop:\n",
    "        \n",
    "        autoencoder.train()\n",
    "        output,_ = autoencoder(bath)\n",
    "        loss = loss_fn(output, bath)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        mass_loss.append(loss.item())\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "    print(f\"Эпоха {epoch+1}, Потери: {np.median(mass_loss):.4f}\")"
   ],
   "id": "ca93f79c95783127",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T11:30:43.664423Z",
     "start_time": "2025-05-24T11:30:41.470797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "autoencoder.eval()\n",
    "out,latent = autoencoder(faces)\n",
    "reconstructed = out.detach().cpu()\n",
    "\n",
    "show_faces(faces.cpu(), reconstructed)\n"
   ],
   "id": "6f508f628d12cbea",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T11:32:04.986145Z",
     "start_time": "2025-05-24T11:32:04.970745Z"
    }
   },
   "cell_type": "code",
   "source": "latent = latent.detach().cpu().numpy()",
   "id": "b55bae345b439195",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T11:32:28.037397Z",
     "start_time": "2025-05-24T11:32:28.021950Z"
    }
   },
   "cell_type": "code",
   "source": "latent.shape",
   "id": "e853f42a4c3b906d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 128)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T12:34:06.766604Z",
     "start_time": "2025-05-24T12:33:58.904199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "autoencoder = SimpleAutoencoder()\n",
    "autoencoder.load_state_dict(torch.load(\"autoencoder_weights.pth\"))\n",
    "autoencoder.to(device)\n",
    "autoencoder.eval()\n",
    "out,latent = autoencoder(faces)\n",
    "reconstructed = out.detach().cpu()\n",
    "show_faces(faces.cpu(), reconstructed)"
   ],
   "id": "6d0f3d70ec003e83",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T12:32:07.919966Z",
     "start_time": "2025-05-24T12:32:07.913389Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "88895843e1029ffe",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "93d060ee5036c3be"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
